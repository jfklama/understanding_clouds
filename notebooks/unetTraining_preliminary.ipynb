{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from understanding_clouds.utils import preproces_dataframe_all_masks, get_all_masks_and_img\n",
    "from understanding_clouds.constants import LABELS_MAPPING\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "from understanding_clouds.torchvision_references.engine import train_one_epoch, evaluate\n",
    "from understanding_clouds.torchvision_references.utils import collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskUnetDataset(Dataset):\n",
    "    def __init__(self, images_dirpath, transforms=None, img_scale_factor=4, subsample=None):\n",
    "        self.images_dirpath = images_dirpath\n",
    "        self._img_scale_factor = 4\n",
    "        df = pd.read_csv(os.path.join(images_dirpath, 'train.csv'))\n",
    "        df = preproces_dataframe_all_masks(df)\n",
    "        self.df = df.iloc[::subsample] if subsample is not None else df\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__ (self, index):\n",
    "        masks, img, labels = get_all_masks_and_img(\n",
    "            self.df, index, os.path.join(self.images_dirpath, 'train_images'), scale_factor=self._img_scale_factor)\n",
    "        \n",
    "        img = cv2.resize(img, (352,528), interpolation=cv2.INTER_AREA)\n",
    "        masks = [cv2.resize(mask, (352,528), interpolation=cv2.INTER_AREA) for mask in masks]\n",
    "        \n",
    "        labels = [LABELS_MAPPING[l] for l in labels]\n",
    "        labels = [l for l in labels if l > 0]\n",
    "        masks_not_empty = []\n",
    "        #for mask in filter(lambda x: np.sum(x) > 0, masks):\n",
    "        #    masks_not_empty.append(mask)\n",
    "        \n",
    "        img_id = torch.tensor([index])\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8) / 255\n",
    "        iscrowd = torch.zeros((len(masks),), dtype=torch.int64)\n",
    "        \n",
    "        img = T.ToTensor()(img)\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        img = img.to('cuda')\n",
    "        masks = masks.to('cuda').float()\n",
    "        \n",
    "        return img, masks\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jfklama/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\n",
    "            'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "    in_channels=3, out_channels=4, init_features=32, pretrained=False).to(device)\n",
    "\n",
    "#model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-01d50bd5564c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mDiceLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'dice_loss'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    __name__ = 'dice_loss'\n",
    "\n",
    "    def __init__(self, eps=1e-7, activation='sigmoid'):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, y_pr, y_gt):\n",
    "        return 1 - f_score(y_pr, y_gt, beta=1., \n",
    "                           eps=self.eps, threshold=None, \n",
    "                           activation=self.activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MaskUnetDataset(images_dirpath = '../data/', subsample = 500)\n",
    "#dataloaders = {'TRAIN': torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)}\n",
    "#dataloaders = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "dataloader = DataLoader( train_dataset, batch_size=1, shuffle=True )\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "gamma = 0.9\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "            optimizer=optimizer, gamma=gamma)\n",
    "\n",
    "experiment_dirpath = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(epoch: int):\n",
    "        os.makedirs(experiment_dirpath, exist_ok=True)\n",
    "        checkpoint = {'epoch': epoch,\n",
    "                      'state_dict': model.state_dict(),\n",
    "                      'optimizer': optimizer.state_dict(),\n",
    "                      'lr_scheduler': lr_scheduler.state_dict()}\n",
    "        torch.save(checkpoint, os.path.join(\n",
    "            experiment_dirpath, 'model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _single_forward_pass(images, targets, phase):\n",
    "        images = [img.cuda() for img in images]\n",
    "        targets = [{k: v.cuda() for k, v in target.items()}\n",
    "                   for target in targets]\n",
    "        # it has a structure of {'loss_type': torch.tensor corresponding to the loss}\n",
    "        loss_dict = model(images)\n",
    "        return loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def train(dataloaders = dataloaders, epochs: int = 10, snapshot_frequency: int = 10):\n",
    "        for i, epoch in enumerate(range(1, epochs + 1)):\n",
    "            for phase, dataloader in dataloaders.items():\n",
    "                if phase == 'TRAIN':\n",
    "                    train_one_epoch(model, optimizer, dataloader, device, epoch, print_freq=len(dataloader) // 5)\n",
    "                    lr_scheduler.step()\n",
    "                else:\n",
    "                    evaluate(model, dataloader, device=device)\n",
    "            if i % snapshot_frequency == 0:\n",
    "                save_model(epoch)\n",
    "        save_model(epoch)\n",
    "'''\n",
    "\n",
    "def train(dataloader = dataloader, epochs: int = 10, snapshot_frequency: int = 10):\n",
    "    \n",
    "    loss_list = []\n",
    "    \n",
    "    for i, epoch in enumerate(range(1, epochs + 1)):\n",
    "        print(f'Epoch {epoch}')\n",
    "        model.train()\n",
    "        \n",
    "        loss_tmp = []\n",
    "        \n",
    "        for image, masks in dataloader:\n",
    "            #print(image[0].shape)\n",
    "            input_batch = image[0].unsqueeze(0).type(torch.cuda.FloatTensor)\n",
    "            input_batch = input_batch.to('cuda')\n",
    "            #image = image.to('cuda')\n",
    "            #masks = masks[0].unsqueeze(0).type(torch.cuda.FloatTensor)\n",
    "            #masks = masks.to('cuda').float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            #output = model(input_batch)\n",
    "            output = model(image)\n",
    "            loss = loss_fn(output, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        '''    \n",
    "        for i in range(len(train_dataset)):\n",
    "                    image, mask = train_dataset[i]\n",
    "                    #image = image.cuda\n",
    "                    #mask = mask.cuda()\n",
    "                    input_batch = image.unsqueeze(0).type(torch.cuda.FloatTensor)\n",
    "                    input_batch = input_batch.to('cuda')\n",
    "                    mask = mask.to('cuda').float()\n",
    "                    \n",
    "                    mask = mask.unsqueeze(0).type(torch.cuda.FloatTensor)\n",
    "                    #print(image.size(), mask.size(), input_batch.size())\n",
    "                    #mask = mask.float()\n",
    "                    #print(type(input_batch))\n",
    "                    \n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    #print(images.shape)\n",
    "                    #with torch.set_grad_enabled(phase == 'TRAIN'):\n",
    "                    #    loss_dict = _single_forward_pass(images, targets, phase)\n",
    "                    #    loss = sum([l for l in loss_dict.values()])\n",
    "                    #    phase_loss += loss.item()\n",
    "                    output = model(input_batch)\n",
    "                    loss = loss_fn(output, mask)\n",
    "                    #print(loss.item())\n",
    "                    loss_tmp.append(loss.item())\n",
    "                    \n",
    "                    #if phase == 'TRAIN':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()'''\n",
    "        loss_list.append( np.mean(loss_tmp) )\n",
    "        lr_scheduler.step()\n",
    "        if i % snapshot_frequency == 0:\n",
    "                save_model(epoch)\n",
    "    print(loss_list) \n",
    "    save_model(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Epoch 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-86-95b38853f7e7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, epochs, snapshot_frequency)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         '''    \n",
      "\u001b[0;32m~/gitprojects/clouds/clouds-env/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitprojects/clouds/clouds-env/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitprojects/clouds/clouds-env/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
